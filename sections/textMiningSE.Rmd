---
title: "Text Mining Soft Eng Data"
output: html_document
---

In software engineering, there is a lot of information that can be extracted from Software Configuration Management System (SCM), or Bug Tracking Systems such as Bugzilla. 



# Classifying bugs from Bugzilla 


Bugzilla is Issue Tracking System that allow us to maintain and track the evolution of a project.
The following example shows how to work with entries from Bugzilla. It is assumed that the data has been extracted and we have the records in a flat file (this can be done using Web crawlers or directly using the SQL database).


```{r message=FALSE, warning=FALSE}
library(foreign)

d <- read.arff("../datasets/textMining/compendium.arff")
head(d,2)
```

Creating a Document-Term Matrix (DTM)

```{r message=FALSE, warning=FALSE}
library(tm)

dfcomp <- data.frame(textCol = d$Description)  # , d$Category)

ds <- DataframeSource(dfcomp)
dsc <-Corpus(ds)

# weighting=TfIdf weighting is Tf-Idf
# minWordLength=WL the minimum word length is WL
# minDocFreq=ND each word must appear at least in ND docs

# Other options of DTM
# These are not really needed, if preprocessing has been carried out:
# stemming=TRUE stemming is applied
# stopwords=TRUE stopwords are eliminated
# removeNumbers=TRUE numbers are eliminated


dtm<- DocumentTermMatrix(dsc, control = list(weighting = weightTfIdf, minDocFreq=3, stopwords = TRUE, removeNumbers = TRUE))

# dim(dtm)
# inspect(dtm) #[1:10,1:10])

# dtm.70=removeSparseTerms(dtm,sparse=0.7)
# dtm.70 # or dim(dtm.70)
# note that the term-document matrix needs to be transformed (casted)
# to a matrix form in the following barplot command

dtm.90=removeSparseTerms(dtm,sparse=0.9)

barplot(as.matrix(dtm),xlab="terms",ylab="number of occurrences",main="Most frequent terms (sparseness=0.9)")
```

As data frame:

```{r results='hide'}
#dtmdf <- as.data.frame(dtm.90)
dtmdf <- as.data.frame(inspect(dtm.90))
# rownames(dtm)<- 1:nrow(dtm)


class <- d$Category
dtmdf <- cbind(dtmdf,class)
```

Now, we can explore things such as "which words are associated with "feature"?"
```{r}
# which words are associated with "feature"?
findAssocs(dtm, 'feature', 0.40)
```

And find frequent terms.

```{r}
findFreqTerms(dtm,5)
```

Use any classifier now:

```{r}
library(caret)
library(randomForest)

inTraining <- createDataPartition(dtmdf$class, p = .75, list = FALSE)
training <- dtmdf[ inTraining,]
testing  <- dtmdf[-inTraining,]

fitControl <- trainControl(## 5-fold CV
                           method = "repeatedcv",
                           number = 5,
                           ## repeated ten times
                           repeats = 5)


gbmFit1 <- train(class ~ ., data = training,
                 method = "gbm",
                 trControl = fitControl,
                 ## This last option is actually one
                 ## for gbm() that passes through
                 verbose = FALSE)

gbmFit1

trellis.par.set(caretTheme())
plot(gbmFit1)

trellis.par.set(caretTheme())
plot(gbmFit1, metric = "Kappa")

head(predict(gbmFit1, testing, type = "prob"))

confusionMatrix(testing$class, predict(gbmFit1, testing))

```


And finally, a word cloud as an example that appears everywhere these days.

```{r}
library(wordcloud)
# calculate the frequency of words and sort in descending order.
wordFreqs=sort(colSums(as.matrix(dtm.90)),decreasing=TRUE)
wordcloud(words=names(wordFreqs),freq=wordFreqs)
```


## Extracting data from Twitter

The hardest bit is to link with Twitter. Using the TwitteR package is explained following this [example](./twitter.Rmd).
